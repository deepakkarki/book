
\section{Introduction}
\label{chap:introduction}

In its classic role, an operating system is a computer program
which abstracts the platform it runs on and provides services to
application software.  Applications in turn provide functionality that
the user of the computer system is interested in.  For the user to be
satisfied, the operating system must therefore support both the platform
and application software.

An operating system is understood to consist of the kernel, userspace
libraries and utilities, although the exact division between these
parts is not definitive in every operating system.  The kernel, as the
name says, contains the most fundamental routines of the operating
system.  In addition to low-level platform support and critical
functionality such as thread scheduling and IPC, the kernel offers
\textit{drivers}, which abstract an underlying entity.  Throughout this
book we will use the term \textit{driver} in an extended sense
which encompasses not only hardware device drivers, but additionally
for example file system drivers and the TCP/IP network driver.

Major contemporary operating systems follow the monolithic kernel model.
Of popular general purpose operating systems, for example Linux, Windows
and Mac~OS~X are regarded as monolithic kernel operating systems.
A monolithic kernel means that the entire kernel is executed in a single
privileged domain, as opposed to being spread out to multiple independent
domains which communicate via message passing.  The single privileged
domain in turn means that all code in the kernel has full capability to
directly control anything running on that particular system.  Furthermore,
the monolithic kernel does not inherently impose any technical
restrictions for the structure of the kernel: a routine may call any other
routine in the kernel and access all memory directly.  However, like
in most disciplines, a well-designed architecture is desirable.
Therefore, even a monolithic kernel tends towards structure.

\subsection{Challenges with the Monolithic Kernel}
\label{sect:challenge}

\begin{quote}
\emph{Tuurilla ne laivatkin seilaa.}

-- Finnish saying about ship navigation
\end{quote}

Despite its widespread popularity, we identified a number of
suboptimal characteristics in monolithic kernels which we consider
as the motivating problems:

\begin{enumerate}
\item   \textbf{Weak security and robustness}.
	Since all kernel code runs in the same privileged domain, a
	single mistake can bring the whole system down.  The fragile
	nature of the monolithic kernel is a long-standing problem to
	which all monolithic kernel operating systems are vulnerable.

	Bugs are an obvious manifestation of the problem,
	but there are more subtle issues to consider.  For instance,
	widely used file system drivers are vulnerable against
	untrusted disk images~\cite{yang:exe}.	This vulnerability is
	acknowledged in the manual page of the mount command for example
	on Linux: ``\textit{It is possible for a corrupted file system
	to cause a crash}''.
	The commonplace act of accessing untrusted removable media such
	as a USB stick or DVD disk with an in-kernel file system driver
	opens the entire system to a security vulnerability.

\item	\textbf{Limited possibilities for code reuse}. The code in a
	monolithic kernel is viewed
	to be an all-or-nothing deal due to a belief that
	everything is intertwined with everything else.
	This belief implies
	that features cannot be cherry-picked and put into use in other
	contexts and that the kernel drivers have value only when they
	are a part of the monolithic kernel.
	Examples include file systems~\cite{yang:exe} and
	networking~\cite{musuvathi:netmodelcheck}.

	One manifestation of this belief is the reimplementation
	of kernel drivers for userspace.  These reimplementations include TCP/IP
	stacks~\cite{dinda:minet,pradhan:daytona} and file system
	drivers~\cite{e2fsprogs, mtools, sun:testfs}~\footnote
	{
		We emphasize that with file systems we do
		\textbf{not} mean FUSE (Filesystem in
		Userspace)~\cite{fuse}.  FUSE provides a mechanism
		for attaching a file system driver as a microkernel
		style server, but does not provide the driver
		itself.  The driver attached by FUSE may be an
		existing kernel driver which was reimplemented in
		userspace~\cite{e2fsprogs, fuseext2}.
	}
	for the purposes of research, testing, teaching and
	application-level drivers.  The common approaches for reimplementation
	are starting from scratch or taking a kernel driver and
	adjusting the code until the specific driver can run in
	userspace.

	If cherry-picking unmodified drivers were possible, kernel
	drivers could be directly used at application level.  Code
	reuse would not only save the initial implementation effort, but
	more importantly it would save from having to
	maintain the second implementation.

\item   \textbf{Development and testing is convoluted}.  This is a
	corollary of the previous point:
	in the general case testing involves booting up the whole
	operating system for each iteration.  Not only is the bootup
	slow in itself, but when it is combined with the fact that an
	error may bring the entire system down, development cycles
	become long and batch mode regression testing is difficult.
	The difficulty of testing affects how much testing and quality
	assurance the final software product receives.	Users are
	indirectly impacted: better testing produces a better system.

	Due to the complexity and slowness of in-kernel development,
	a common approach is to implement a prototype in userspace
	before porting the code to the kernel.  For example FFS in
	BSD and ZFS in
	Solaris~\cite{bonwick:zfs} were implemented this way.  This
	approach may bring additional work when the code is being
	moved into the kernel, as the support shim in userspace
	may not have fully emulated all kernel
	interfaces.
\end{enumerate}

\subsection{Researching Solutions}

One option for addressing problems in monolithic kernels is designing
a better model and starting from scratch.  Some examples of
alternative kernel models include the
microkernel~\cite{accetta:mach,herder:minix3,hildebrand:qnx,liedtke:construction}
Exokernel~\cite{engler:exo} and
a partitioned kernel~\cite{baumann:multikernel,wentzlaff:casefos}.  The
problem with starting from scratch is getting to the point of having
enough support for external protocols to be a viable alternative for
evaluation with real world applications.  These external protocols
include anything serviced by a driver and range from a networking
stack to a POSIX interface.  As the complexity of the operating
environment and external restrictions grow, it is more and more
difficult to start working on an operating system from
scratch~\cite{pike:irrelevant}.  For a figure on the amount of code
in a modern OS, we look at two subsystems in the Linux 3.3 kernel
from March 2012.  There are 1,001,218 physical lines
of code for file system drivers in the \texttt{fs} subdirectory and
711,150 physical lines of code for networking drivers in the \texttt{net}
subdirectory (the latter figure does not include NIC drivers, which are
kept elsewhere in the source tree).  For the sake of discussion, let us
assume that a person who can write 100~lines of bugfree code each day
writes all of those drivers.  In that case, it will take over 46 years to
produce the drivers in those subdirectories.

Even if there are resources to write a set of drivers from scratch,
the drivers have not been tested in production in the real world when they
are first put out.  Studies show that new code contains the most
faults~\cite{chou:oserr,ostrand:faultdist}.  The faults do not exist
because the code would have been poorly tested before release, but rather
because it is not possible to anticipate every real world condition in a
laboratory environment.  We argue that real world use is the property that
makes an existing driver base valuable, not just the fact that it exists.

\subsection{Thesis}
\label{sect:thesis}

We claim that it is possible to construct a flexible kernel architecture
which solves the challenges listed in Section~\ref{sect:challenge}, and
yet retain the monolithic kernel.  Furthermore, it is possible to
implement the flexible kernel architecture solely by good programming
principles and without introducing levels of indirection which hinder
the monolithic kernel's performance characteristics.  We show our claim
to be true by an implementation for a BSD-derived open source monolithic
kernel OS, NetBSD~\cite{NetBSD}.

We define an \textit{anykernel} to be an organization of kernel code
which allows the kernel's \textit{unmodified} drivers to be run in
various configurations such as application libraries and microkernel
style servers, and also as part of a monolithic kernel.  This
approach leaves the configuration the driver is used in to be
decided at runtime.  For example, if maximal performance is
required, the driver can be included in a monolithic kernel, but
where there is reason to suspect stability or security, the driver
can still be used as an isolated, non-privileged server where
problems cannot compromised the entire system.

An anykernel can be instantiated into units which virtualize the
bare minimum support functionality for kernel drivers.  We call these
virtualized kernel instances \textit{rump kernels}
since they retain only a part of the original kernel.  This
minimalistic approach makes rump kernels fast to bootstrap (\~{ }10ms)
and introduces only a small memory overhead (\~{ }1MB per instance).

The platform that the rump kernel is running on is called the host
platform or \textit{host}.  Examples of supported host platforms include
userspace processes on most POSIX-like operating systems and the Xen
hypervisor.  To showcase how rump kernels can be made to run on virtually
any platform, an experiment was done where rump kernels were compiled
to javascript (instead of assembly) and ran natively in web browsers.

At runtime, a rump kernel can assume the role of an application library
or that of a server.  Programs requesting services from rump kernels
are called rump kernel clients.  Throughout this book we use
the shorthand \textit{client} to denote rump kernel clients.
We define three client types.

\begin{enumerate}
\item	Local: the rump kernel is used in a library capacity.
	Like with any library, using the rump kernel as a library requires
	that the application is written to use APIs provided by a rump
	kernel.  The main API for a local client is a system call API
	with the same call signatures as on a regular NetBSD system.

	For example, it is possible to use a kernel file system driver as
	a library in an application which interprets a file system image.

\item   Microkernel: the host routes client requests from regular
	processes to drivers running in isolated servers.
	Unmodified application binaries can be used.

	For example, it is possible to run a block device driver as a
	microkernel style server, with the kernel driver outside the
	privileged domain.

\item   Remote: the client and rump kernel are running in
	different containers (processes) with the client deciding
	which services to request from the rump kernel and which to
	request from the host kernel.  For example, the client can
	use the TCP/IP networking services provided by a rump
	kernel.  The kernel and client can exist either on the same
	host or on different hosts.  In this model, both
	specifically written applications and unmodified applications
	can use services provided by a rump kernel.  The API for
	specifically written applications is the same as for local
	clients.

	For example, it is possible to use an unmodified Firefox web
	browser with the TCP/IP code running in a rump kernel server.
\end{enumerate}

Each configuration contributes to solving our motivating problems:

\begin{enumerate}
\item   \textbf{Security and robustness}.
	When necessary, the use of a rump kernel will allow unmodified
	kernel drivers to be run as isolated microkernel servers
	while preserving the user experience.  At other times the
	same driver code can be run in the original fashion as part
	of the monolithic kernel.

\item	\textbf{Code reuse}.  A rump kernel may be used by an
	application in the same fashion as any other userlevel
	library.  A local client can call any routine inside the
	rump kernel.

\item	\textbf{Development and testing}.  The lightweight nature
	and safety properties of a rump kernel allow for safe testing
	of kernel code with iteration times in the millisecond range.
	The remote client model enables the creation of tests using
	familiar tools.
\end{enumerate}

Our implementation supports rump kernels for file systems (\eg FFS),
networking (\eg TCP/IP) and device drivers (\eg PCI).  Both synthetic
benchmarks and real world data gathered from a period between 2007 and
2011 are used for the evaluation.


\subsection{Book Outline}

\chapref{concept} defines the concept of an anykernel and explains
rump kernels.
\chapref{implementation} discusses the implementation and provides
microbenchmarks as supporting evidence for implementation decisions.
\chapref{evaluation} evaluates the solution.
\chapref{related} looks at related work.
\chapref{conclusions} provides concluding remarks.


\subsection{Further Material}

\subsubsection{Source Code}
\label{sect:src}

The basis of rump kernels is formed by the NetBSD operating system.
For example, the majority of the drivers and the general infrastructure
is directly used from the NetBSD source repository.
The NetBSD files histories are available for study from repository
provided by the NetBSD project, \eg via the web interface at
\texttt{cvsweb.NetBSD.org}.

Additionally, there is infrastructure to support building rump kernels
for various platforms, hosted at \texttt{http://repo.rumpkernel.org/}.

The easiest way to fetch the NetBSD source code is to run the following
commands:

\begin{verbatim}
git clone http://repo.rumpkernel.org/buildrump.sh
cd buildrump.sh
./buildrump.sh checkout
\end{verbatim}

Unlike in the original dissertation, we do not define exact revisions
for the source code we describe in this book.  However, we attempt to
keep all discussion in such a state that it is fully up-to-date whenever
a new version of the book is released.

\subsubsection*{Code examples}

This book includes code examples from the NetBSD source
tree.  All such examples are copyright of their respective owners
and are not public domain.  If pertinent, please check the full
source for further information about the licensing and copyright
of each such example.

\subsubsection{Manual Pages}

Various manual pages are cited in the document.  They are available
as part of the NetBSD distribution, or via the web interface
at \texttt{http://man.NetBSD.org/}.
